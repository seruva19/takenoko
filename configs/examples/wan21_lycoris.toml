# Takenoko WAN21 LyCORIS Fine-Tuning Configuration
# Optimized configuration for WAN21 T2V 14B model LyCORIS fine-tuning

# =============================================================================
# TARGET TRAINING
# =============================================================================

target_model = "wan21" 

# =============================================================================
# CHECKPOINT SETTINGS
# =============================================================================

dit = "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_t2v_14B_fp16.safetensors" 
fp8_base = true 
vae = "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors"
t5 = "https://huggingface.co/Wan-AI/Wan2.1-T2V-14B/resolve/main/models_t5_umt5-xxl-enc-bf16.pth"

# =============================================================================
# TRAINING SETTINGS
# =============================================================================

max_train_steps = 10000 
max_data_loader_n_workers = 2 
persistent_data_loader_workers = true 
seed = 20250811 
gradient_checkpointing = true 
gradient_accumulation_steps = 1 
mixed_precision = "fp16" 

# =============================================================================
# OPTIMIZER SETTINGS
# =============================================================================

optimizer_type = "adamw8bit" 
learning_rate = 2.0e-5 
max_grad_norm = 1.0 

# =============================================================================
# LEARNING RATE SCHEDULER
# =============================================================================

lr_scheduler = "constant" 
lr_warmup_steps = 0 
lr_decay_steps = 0 
lr_scheduler_num_cycles = 1 
lr_scheduler_power = 1.0 

# =============================================================================
# NETWORK SETTINGS
# =============================================================================

network_module = "lycoris.kohya" 
network_dim = 8 
network_alpha = 1 

# https://github.com/KohakuBlueleaf/LyCORIS/blob/main/docs/Network-Args.md
network_args = [
  # Core Algorithm and Preset Settings
  "algo=lokr",                          # Algorithm type: lora, lokr, loha, ia3, etc. (default: lora)
  "preset=attn-mlp",                    # Preset configuration: full, attn-only, mlp-only, attn-mlp, etc. (default: full)
  
  # Dimension and Alpha Settings
  "conv_dim=8",                         # Dimension of convolutional layers (default: network_dim)
  "conv_alpha=1.0",                     # Alpha of convolutional layers (default: network_alpha)
  
  # Dropout Settings
  "dropout=0",                          # General dropout rate (default: 0.0)
  "rank_dropout=0",                     # Dropout for rank adaptation (default: 0.0)
  "module_dropout=0",                   # Dropout for modules (default: 0.0)
  
  # LoKr Specific Settings
  "factor=8",                           # Factor for LoKr algorithm (default: -1)
  "decompose_both=False",               # Decompose both matrices for LoKr (default: False)
  
  # DyLoRA Settings
  "block_size=4",                       # Block size for DyLoRA (default: 4)
  
  # Tucker Decomposition
  "use_tucker=False",                   # Use Tucker decomposition (default: False)
  
  # Scalar Adaptation
  "use_scalar=False",                   # Use scalar adaptation for LoRA/LoHa/LoKr (default: False)
  
  # Weight Decomposition (DoRA)
  "dora_wd=False",                      # Enable DoRA weight decomposition (default: False)
  
  # Bypass Mode
  "bypass_mode=False",                  # Use Y=WX+ΔWX instead of Y=(W+ΔW)X (default: False)
  
  # Normalization Layers
  "train_norm=False",                   # Train normalization layers (default: False)
  
  # Diag-OFT Settings
  "rescaled=True",                      # Enable rescaled OFT (default: False)
  "constraint=0.0",                     # Constraint value for constrained OFT (default: 0.0)
  
  # Additional Settings
  "full_matrix=True",                   # Use full matrix mode for LoKr (default: False)
  "use_tucker=False",                   # Use convolution checkpointing (default: False)
  "wd_on_output=True",                  # Weight decomposition on output (default: True)
  "rs_lora=False",                      # Use RS-LoRA (default: False)
  "unbalanced_factorization=False",     # Use unbalanced factorization (default: False)
  "train_t5xxl=False"                   # Train T5-XXL model (default: False)
] # additional arguments for network (key=value)

lycoris = true 

# =============================================================================
# TIMESTEP AND FLOW MATCHING SETTINGS
# =============================================================================

timestep_sampling = "shift" 
discrete_flow_shift = 3.0 
sigmoid_scale = 1.0 
weighting_scheme = "none" 
logit_mean = 0.0 
logit_std = 1.0 
mode_scale = 1.29 

# =============================================================================
# OPTIMIZATION SETTINGS
# =============================================================================

sdpa = true 

# =============================================================================
# METADATA SETTINGS
# =============================================================================

embed_config_in_metadata = true 

# =============================================================================
# OUTPUT SETTINGS
# =============================================================================

output_dir = "output/wan21_lycoris" 
output_name = "wan21_lycoris" 
save_state = true 
save_every_n_steps = 500 
auto_resume = true 

# =============================================================================
# LOGGING SETTINGS
# =============================================================================

enhanced_progress_bar = true 
log_config = true 
logging_dir = "logs/wan21_lycoris" 
log_with = "tensorboard" 
logging_level = "INFO" 
launch_tensorboard_server = true 
tensorboard_host = "127.0.0.1" 
tensorboard_port = 6006 
tensorboard_auto_reload = true 

# =============================================================================
# VALIDATION SETTINGS
# =============================================================================

validate_every_n_steps = 500 
validation_timesteps = "100,300,500,700,900" 
use_unique_noise_per_batch = true 

# =============================================================================
# SAMPLING SETTINGS
# =============================================================================

sample_every_n_steps = 500 
sample_at_first = true 

# =============================================================================
# SAMPLE PROMPTS SETTINGS
# =============================================================================

[[sample_prompts]]

text = """
Young woman with short blonde hair and grey eyes, tank top, denim shorts, \
in a cluttered open restaurant on a hill above amazing ocean beach
"""
width = 384 
height = 384 
frames = 45 
seed = 20250801 
step = 20 
cfg_scale = 6.0 

# =============================================================================
# LATENT CACHE SETTINGS
# =============================================================================

[datasets.latent_cache]

vae_cache_cpu = true 
vae_dtype = "float16" 
device = "cuda" 
skip_existing = false 
keep_cache = true 

# =============================================================================
# TEXT ENCODER CACHE SETTINGS
# =============================================================================

[datasets.text_encoder_cache]

fp8_t5 = true 
device = "cuda" 
batch_size = 16 
skip_existing = false 
keep_cache = true 

# =============================================================================
# DATASET SETTINGS
# =============================================================================

[datasets.general] 

caption_extension = ".txt" 
enable_bucket = true 
bucket_no_upscale = true 

# =============================================================================
# TRAINING DATASETS
# =============================================================================

[[datasets.train]] 

image_directory = "path/to/images" 
cache_directory = "path/to/images/cache" 
resolution = [512, 512] 
batch_size = 1 
num_repeats = 1 

[[datasets.train]] 

video_directory = "path/to/videos" 
cache_directory = "path/to/videos/cache" 
resolution = [256, 256] 
batch_size = 1 
num_repeats = 1 
frame_extraction = "uniform" 
target_frames = [1, 17, 33] 
frame_sample = 1 

# =============================================================================
# VALIDATION DATASETS
# =============================================================================

[[datasets.val]]  

image_directory = "path/to/val/images" 
cache_directory = "path/to/val/images/cache" 
resolution = [512, 512] 
batch_size = 1 
num_repeats = 1 

[[datasets.val]] 

video_directory = "path/to/val/videos" 
cache_directory = "path/to/val/videos/cache" 
resolution = [256, 256] 
batch_size = 1 
num_repeats = 1 
frame_extraction = "head" 
target_frames = [1, 25] 
frame_sample = 1 
